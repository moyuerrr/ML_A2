{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 设置路径\n",
    "train_feature_dir = '../2025_A2/train/Features'\n",
    "train_metadata_path = '../2025_A2/train/train_metadata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                int64\n",
      "edge_density    float64\n",
      "mean_b          float64\n",
      "mean_g          float64\n",
      "mean_r          float64\n",
      "                 ...   \n",
      "hog_pca_15      float64\n",
      "hog_pca_16      float64\n",
      "hog_pca_17      float64\n",
      "hog_pca_18      float64\n",
      "hog_pca_19      float64\n",
      "Length: 121, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 读取特征数据\n",
    "color_df = pd.read_csv(os.path.join(train_feature_dir, 'color_histogram.csv'))\n",
    "hog_df = pd.read_csv(os.path.join(train_feature_dir, 'hog_pca.csv'))\n",
    "additional_df = pd.read_csv(os.path.join(train_feature_dir, 'additional_features.csv'))\n",
    "\n",
    "def merge(meta):\n",
    "    return (meta\n",
    "            .merge(additional_df,  on=\"image_path\")\n",
    "            .merge(color_df, on=\"image_path\")\n",
    "            .merge(hog_df,    on=\"image_path\"))\n",
    "\n",
    "metadata_df = pd.read_csv(train_metadata_path)\n",
    "\n",
    "# 合并特征\n",
    "X = merge(metadata_df).drop(columns=[\"ClassId\", \"image_path\"])\n",
    "\n",
    "print(X.dtypes)  # 确保所有列都是 float 或 int 类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取标签\n",
    "metadata_df = pd.read_csv(train_metadata_path)\n",
    "y = metadata_df['ClassId']\n",
    "y_encoded = to_categorical(y, num_classes=43)\n",
    "\n",
    "# 特征标准化\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 划分训练集与验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_encoded, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "78/78 [==============================] - 1s 4ms/step - loss: 3.2147 - accuracy: 0.1796 - val_loss: 2.3411 - val_accuracy: 0.4372\n",
      "Epoch 2/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 2.1005 - accuracy: 0.4141 - val_loss: 1.4586 - val_accuracy: 0.5519\n",
      "Epoch 3/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 1.5388 - accuracy: 0.5224 - val_loss: 1.1151 - val_accuracy: 0.6630\n",
      "Epoch 4/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 1.2245 - accuracy: 0.6127 - val_loss: 0.9317 - val_accuracy: 0.6995\n",
      "Epoch 5/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 1.0904 - accuracy: 0.6441 - val_loss: 0.8662 - val_accuracy: 0.7250\n",
      "Epoch 6/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.9443 - accuracy: 0.6876 - val_loss: 0.7778 - val_accuracy: 0.7486\n",
      "Epoch 7/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.8388 - accuracy: 0.7222 - val_loss: 0.7311 - val_accuracy: 0.7596\n",
      "Epoch 8/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.7724 - accuracy: 0.7457 - val_loss: 0.6673 - val_accuracy: 0.7960\n",
      "Epoch 9/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.7310 - accuracy: 0.7564 - val_loss: 0.6519 - val_accuracy: 0.7778\n",
      "Epoch 10/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.7710 - val_loss: 0.6191 - val_accuracy: 0.7814\n",
      "Epoch 11/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.7878 - val_loss: 0.6627 - val_accuracy: 0.7760\n",
      "Epoch 12/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.7925 - val_loss: 0.6233 - val_accuracy: 0.7760\n",
      "Epoch 13/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.8048 - val_loss: 0.6305 - val_accuracy: 0.7887\n",
      "Epoch 14/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.8162 - val_loss: 0.5906 - val_accuracy: 0.7996\n",
      "Epoch 15/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.8291 - val_loss: 0.5695 - val_accuracy: 0.7978\n",
      "Epoch 16/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.8313 - val_loss: 0.5668 - val_accuracy: 0.8124\n",
      "Epoch 17/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8469 - val_loss: 0.5598 - val_accuracy: 0.8233\n",
      "Epoch 18/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8532 - val_loss: 0.5481 - val_accuracy: 0.8179\n",
      "Epoch 19/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.8411 - val_loss: 0.5346 - val_accuracy: 0.8270\n",
      "Epoch 20/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8540 - val_loss: 0.5281 - val_accuracy: 0.8306\n",
      "Epoch 21/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8595 - val_loss: 0.5547 - val_accuracy: 0.8324\n",
      "Epoch 22/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8627 - val_loss: 0.5571 - val_accuracy: 0.8342\n",
      "Epoch 23/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8777 - val_loss: 0.5593 - val_accuracy: 0.8179\n",
      "Epoch 24/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8747 - val_loss: 0.5173 - val_accuracy: 0.8251\n",
      "Epoch 25/25\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.8850 - val_loss: 0.5013 - val_accuracy: 0.8251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c843e6aa90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 搭建神经网络模型\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(43, activation='softmax')  # 43类\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=25, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 886us/step - loss: 0.5013 - accuracy: 0.8251\n",
      "\n",
      "Validation Accuracy: 0.8251\n"
     ]
    }
   ],
   "source": [
    "# 评估验证集准确率\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"\\nValidation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型（可选）\n",
    "model.save('../models/neural_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 762us/step\n"
     ]
    }
   ],
   "source": [
    "feature_dir_test = '../2025_A2/test/Features'\n",
    "meta_path_test = '../2025_A2/test/test_metadata.csv'\n",
    "\n",
    "color_df_test = pd.read_csv(f\"{feature_dir_test}/color_histogram.csv\")\n",
    "hog_df_test = pd.read_csv(f\"{feature_dir_test}/hog_pca.csv\")\n",
    "additional_df_test = pd.read_csv(f\"{feature_dir_test}/additional_features.csv\")\n",
    "def merge_test(meta):\n",
    "    return (meta\n",
    "            .merge(additional_df_test,  on=\"image_path\")\n",
    "            .merge(color_df_test, on=\"image_path\")\n",
    "            .merge(hog_df_test,    on=\"image_path\"))\n",
    "\n",
    "metadata_df_test = pd.read_csv(meta_path_test)\n",
    "\n",
    "X_test = merge_test(metadata_df_test).drop(columns=[\"ClassId\", \"image_path\"])\n",
    "\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "proba_nn_test = model.predict(X_test_scaled)\n",
    "y_pred_test = np.argmax(proba_nn_test, axis=1)\n",
    "test_ids = pd.read_csv(meta_path_test)['id']\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'ClassId': y_pred_test\n",
    "})\n",
    "submission.to_csv('../nn.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
